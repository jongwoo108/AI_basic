{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 딥 러닝을 이용한 자연어 처리 입문"
      ],
      "metadata": {
        "id": "MEALjQmtbuup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[구글 코랩에서 실행하기](https://colab.research.google.com/drive/1H8qsQyuv5fshKJEHPqDtSvQfM1Yxo57m?usp=sharing)"
      ],
      "metadata": {
        "id": "afbHNDH3bwXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://wikidocs.net/111476"
      ],
      "metadata": {
        "id": "G1HwvCJnb19f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "06-06 로지스틱 회귀 실습"
      ],
      "metadata": {
        "id": "OKhSxLdxb3bD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 케라스로 구현하는 로지스틱 회귀"
      ],
      "metadata": {
        "id": "YTnX3BAlb5A0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "독립 변수 데이터를 x\n",
        ", 숫자 10 이상인 경우에는 1, 미만인 경우에는 0을 부여한 레이블 데이터를 y\n",
        "라고 해봅시다.\n",
        "\n",
        "이번 데이터는 앞서 배운 단순 선형 회귀때와 마찬가지로 1개의 실수 x\n",
        "로부터 1개의 실수인 y\n",
        "를 예측하는 맵핑 관계를 가지므로 Dense의 output_dim, input_dim 인자값으로 각각 1을 기재합니다. 시그모이드 함수를 사용할 것이므로 activation의 인자값으로는 sigmoid를 기재해줍니다.\n",
        "\n",
        "옵티마이저로는 가장 기본적인 경사 하강법인 sgd를 사용하였습니다. 시그모이드 함수를 사용한 이진 분류 문제에 손실 함수로 크로스 엔트로피 함수를 사용할 경우 binary_crossentropy를 기재해주면 됩니다. 에포크는 200으로 합니다."
      ],
      "metadata": {
        "id": "xCEzxG49cA9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers"
      ],
      "metadata": {
        "id": "youro-GicGoP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])\n",
        "y = np.array([0,0,0,0,0,0,0,0,1,1,1,1,1]) #숫자 10부터 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1, activation = 'sigmoid'))\n",
        "\n",
        "sgd = optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
        "\n",
        "model.fit(x, y, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LRFAvyYcRgr",
        "outputId": "b006f56b-4f75-4a89-d044-2fd5f5cc8dc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.3626 - binary_accuracy: 0.9231\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3611 - binary_accuracy: 0.9231\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3596 - binary_accuracy: 0.9231\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3581 - binary_accuracy: 0.9231\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3566 - binary_accuracy: 0.9231\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3551 - binary_accuracy: 0.9231\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3536 - binary_accuracy: 0.9231\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3521 - binary_accuracy: 0.9231\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3507 - binary_accuracy: 0.9231\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3492 - binary_accuracy: 0.9231\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3477 - binary_accuracy: 0.9231\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3462 - binary_accuracy: 0.9231\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3447 - binary_accuracy: 0.9231\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3433 - binary_accuracy: 0.9231\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3418 - binary_accuracy: 0.9231\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3403 - binary_accuracy: 0.9231\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3389 - binary_accuracy: 0.9231\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3374 - binary_accuracy: 0.9231\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3359 - binary_accuracy: 0.9231\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3345 - binary_accuracy: 0.9231\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3330 - binary_accuracy: 0.9231\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3316 - binary_accuracy: 0.9231\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3301 - binary_accuracy: 0.9231\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3287 - binary_accuracy: 0.9231\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3272 - binary_accuracy: 0.9231\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3258 - binary_accuracy: 0.9231\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3244 - binary_accuracy: 0.9231\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3229 - binary_accuracy: 0.9231\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3215 - binary_accuracy: 0.9231\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3201 - binary_accuracy: 0.9231\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3186 - binary_accuracy: 0.9231\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3172 - binary_accuracy: 0.9231\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3158 - binary_accuracy: 0.9231\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3144 - binary_accuracy: 0.9231\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3130 - binary_accuracy: 0.9231\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3116 - binary_accuracy: 0.9231\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3102 - binary_accuracy: 0.9231\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3088 - binary_accuracy: 0.9231\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3074 - binary_accuracy: 0.9231\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3060 - binary_accuracy: 0.9231\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3046 - binary_accuracy: 0.9231\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3032 - binary_accuracy: 0.9231\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3019 - binary_accuracy: 0.9231\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3005 - binary_accuracy: 0.9231\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2991 - binary_accuracy: 0.9231\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2978 - binary_accuracy: 0.9231\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2964 - binary_accuracy: 0.9231\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2950 - binary_accuracy: 0.9231\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2937 - binary_accuracy: 0.9231\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2923 - binary_accuracy: 0.9231\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2910 - binary_accuracy: 0.9231\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2897 - binary_accuracy: 0.9231\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2883 - binary_accuracy: 0.9231\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2870 - binary_accuracy: 0.9231\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2857 - binary_accuracy: 0.9231\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2844 - binary_accuracy: 0.9231\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2831 - binary_accuracy: 0.9231\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2818 - binary_accuracy: 0.9231\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2805 - binary_accuracy: 0.9231\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2792 - binary_accuracy: 0.9231\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2779 - binary_accuracy: 0.9231\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2766 - binary_accuracy: 0.9231\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2753 - binary_accuracy: 0.9231\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2740 - binary_accuracy: 0.9231\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2728 - binary_accuracy: 0.9231\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2715 - binary_accuracy: 0.9231\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2702 - binary_accuracy: 0.9231\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2690 - binary_accuracy: 0.9231\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2678 - binary_accuracy: 0.9231\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2665 - binary_accuracy: 0.9231\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2653 - binary_accuracy: 0.9231\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2641 - binary_accuracy: 0.9231\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2628 - binary_accuracy: 0.9231\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2616 - binary_accuracy: 0.9231\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2604 - binary_accuracy: 0.9231\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2592 - binary_accuracy: 0.9231\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2580 - binary_accuracy: 0.9231\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2568 - binary_accuracy: 0.9231\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2557 - binary_accuracy: 0.9231\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2545 - binary_accuracy: 0.9231\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2533 - binary_accuracy: 0.9231\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2522 - binary_accuracy: 0.9231\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2510 - binary_accuracy: 0.9231\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2499 - binary_accuracy: 0.9231\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2488 - binary_accuracy: 0.9231\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2476 - binary_accuracy: 0.9231\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2465 - binary_accuracy: 0.9231\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2454 - binary_accuracy: 0.9231\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2443 - binary_accuracy: 0.9231\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2432 - binary_accuracy: 0.9231\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2421 - binary_accuracy: 0.9231\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2410 - binary_accuracy: 0.9231\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2400 - binary_accuracy: 0.9231\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2389 - binary_accuracy: 0.9231\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2378 - binary_accuracy: 0.9231\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2368 - binary_accuracy: 0.9231\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2358 - binary_accuracy: 0.9231\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2347 - binary_accuracy: 0.9231\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2337 - binary_accuracy: 0.9231\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2327 - binary_accuracy: 0.9231\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2317 - binary_accuracy: 0.9231\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2307 - binary_accuracy: 0.9231\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2297 - binary_accuracy: 0.9231\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2287 - binary_accuracy: 0.9231\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2278 - binary_accuracy: 0.9231\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2268 - binary_accuracy: 0.9231\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2259 - binary_accuracy: 0.9231\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2249 - binary_accuracy: 0.9231\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2240 - binary_accuracy: 0.9231\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2231 - binary_accuracy: 0.9231\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2222 - binary_accuracy: 0.9231\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2213 - binary_accuracy: 0.9231\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2204 - binary_accuracy: 0.9231\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2195 - binary_accuracy: 0.9231\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2186 - binary_accuracy: 0.9231\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2177 - binary_accuracy: 0.9231\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2169 - binary_accuracy: 0.9231\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2160 - binary_accuracy: 0.9231\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2152 - binary_accuracy: 0.9231\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2144 - binary_accuracy: 0.9231\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2136 - binary_accuracy: 0.9231\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2128 - binary_accuracy: 0.9231\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2120 - binary_accuracy: 0.9231\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2112 - binary_accuracy: 0.9231\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2104 - binary_accuracy: 0.9231\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2097 - binary_accuracy: 0.9231\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2089 - binary_accuracy: 0.9231\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2082 - binary_accuracy: 0.9231\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2074 - binary_accuracy: 0.9231\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2067 - binary_accuracy: 0.9231\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2060 - binary_accuracy: 0.9231\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2053 - binary_accuracy: 0.9231\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2046 - binary_accuracy: 0.9231\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2039 - binary_accuracy: 0.9231\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2032 - binary_accuracy: 0.9231\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2026 - binary_accuracy: 0.9231\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2019 - binary_accuracy: 0.9231\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2013 - binary_accuracy: 0.9231\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2007 - binary_accuracy: 0.9231\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2000 - binary_accuracy: 0.9231\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1994 - binary_accuracy: 0.9231\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1988 - binary_accuracy: 0.9231\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1982 - binary_accuracy: 0.9231\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1977 - binary_accuracy: 0.9231\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1971 - binary_accuracy: 0.9231\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1965 - binary_accuracy: 0.9231\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1960 - binary_accuracy: 0.9231\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1954 - binary_accuracy: 0.9231\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1949 - binary_accuracy: 0.9231\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1944 - binary_accuracy: 0.9231\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1939 - binary_accuracy: 0.9231\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1934 - binary_accuracy: 0.9231\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1929 - binary_accuracy: 0.9231\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1924 - binary_accuracy: 0.9231\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1919 - binary_accuracy: 0.9231\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1914 - binary_accuracy: 0.9231\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1910 - binary_accuracy: 0.9231\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1905 - binary_accuracy: 0.9231\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1901 - binary_accuracy: 0.9231\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1897 - binary_accuracy: 0.9231\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1892 - binary_accuracy: 0.9231\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1888 - binary_accuracy: 0.9231\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1884 - binary_accuracy: 0.9231\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1880 - binary_accuracy: 0.9231\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1876 - binary_accuracy: 0.9231\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1872 - binary_accuracy: 0.9231\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1869 - binary_accuracy: 0.9231\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1865 - binary_accuracy: 0.9231\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1862 - binary_accuracy: 0.9231\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1858 - binary_accuracy: 0.9231\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1855 - binary_accuracy: 0.9231\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1851 - binary_accuracy: 0.9231\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1848 - binary_accuracy: 0.9231\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1845 - binary_accuracy: 0.9231\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1842 - binary_accuracy: 0.9231\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1839 - binary_accuracy: 0.9231\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1835 - binary_accuracy: 0.9231\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1833 - binary_accuracy: 0.9231\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1830 - binary_accuracy: 0.9231\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1827 - binary_accuracy: 0.9231\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1824 - binary_accuracy: 0.9231\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1821 - binary_accuracy: 0.9231\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1819 - binary_accuracy: 0.9231\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1816 - binary_accuracy: 0.9231\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1814 - binary_accuracy: 0.9231\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1811 - binary_accuracy: 0.9231\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1809 - binary_accuracy: 0.9231\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1806 - binary_accuracy: 0.9231\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1804 - binary_accuracy: 0.9231\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1802 - binary_accuracy: 0.9231\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1800 - binary_accuracy: 0.9231\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1797 - binary_accuracy: 0.9231\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1795 - binary_accuracy: 0.9231\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1793 - binary_accuracy: 0.9231\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1791 - binary_accuracy: 0.9231\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1789 - binary_accuracy: 0.9231\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1787 - binary_accuracy: 0.9231\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1785 - binary_accuracy: 0.9231\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1783 - binary_accuracy: 0.9231\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1782 - binary_accuracy: 0.9231\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7aa31be2c0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "총 200회에 걸쳐 전체 데이터에 대한 오차를 최소화하는 w\n",
        "와 b\n",
        "를 찾아내는 작업을 합니다. 저자의 경우 약 190회부터 정확도가 100%가 나오기 시작했습니다. 실제값과 오차를 최소화하도록 값이 변경된 w\n",
        "와 b\n",
        "의 값을 가진 모델을 이용하여 그래프를 그려보겠습니다."
      ],
      "metadata": {
        "id": "acS7mX3Fc1Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x, model.predict(x), 'b', x, y, 'k.')\n",
        "plt.grid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "o-bNS05oc63v",
        "outputId": "c644347d-20c5-470f-875f-54b592823860"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "x의 값이 5와 10사이의 어떤 값일때 y\n",
        "값이 0.5가 넘기 시작하는 것처럼 보입니다. 정확도가 100%가 나왔었기 때문에 적어도 x\n",
        "의 값이 5일때는 y\n",
        "값이 0.5보다 작고, x\n",
        "의 값이 10일 때는 y\n",
        "값이 0.5를 넘을 것입니다. 이제 x\n",
        "의 값이 5보다 작은 값일 때와 x\n",
        "의 값이 10보다 클 때에 대해서 y\n",
        "값을 출력해봅시다."
      ],
      "metadata": {
        "id": "uzoRJNukc-qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([1, 2, 3, 4, 4.5]))\n",
        "print(model.predict([11, 21, 31, 41, 500]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE1wx6cIdP4n",
        "outputId": "ea78d08d-63b7-40ce-c0ed-80ac70ae830b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 123ms/step\n",
            "[[0.50910896]\n",
            " [0.5730246 ]\n",
            " [0.63459116]\n",
            " [0.6920511 ]\n",
            " [0.7188182 ]]\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "[[0.931761  ]\n",
            " [0.99446815]\n",
            " [0.99957764]\n",
            " [0.99996793]\n",
            " [1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r04rQnhcdW1l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}