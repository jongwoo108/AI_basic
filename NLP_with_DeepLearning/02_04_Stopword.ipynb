{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 딥 러닝을 이용한 자연어 처리 입문"
      ],
      "metadata": {
        "id": "uo2meRhiJQjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[구글 코랩에서 실행하기](https://colab.research.google.com/drive/1T-XbhfHbsAtATnvqEOD3WWu1yH3YKmJ0?usp=sharing)"
      ],
      "metadata": {
        "id": "nl_Wftt0JYGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "갖고 있는 데이터에서 유의미한 단어 토큰만을 선별하기 위해서는 큰 의미가 없는 단어 토큰을 제거하는 작업이 필요합니다. 여기서 큰 의미가 없다라는 것은 자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어들을 말합니다. 예를 들면, I, my, me, over, 조사, 접미사 같은 단어들은 문장에서는 자주 등장하지만 실제 의미 분석을 하는데는 거의 기여하는 바가 없는 경우가 있습니다. 이러한 단어들을 불용어(stopword)라고 하며, NLTK에서는 위와 같은 100여개 이상의 영어 단어들을 불용어로 패키지 내에서 미리 정의하고 있습니다.\n",
        "\n",
        "불용어는 개발자가 직접 정의할 수도 있습니다. 이번에는 영어 문장에서 NLTK가 정의한 영어 불용어를 제거하는 실습을 하고, 한국어 문장에서 직접 정의한 불용어를 제거해보겠습니다."
      ],
      "metadata": {
        "id": "yg1VCwlOJhN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import gensim\n",
        "import os\n",
        "import nltk\n",
        "import sklearn\n",
        "\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "print(gensim.__version__)\n",
        "print(sklearn.__version__)\n",
        "print(nltk.__version__)"
      ],
      "metadata": {
        "id": "Q4oH7ySjJnz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4cd5da3-34aa-49ba-bb41-accf1f602dff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "2.12.0\n",
            "4.3.1\n",
            "1.2.2\n",
            "3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JTNUepYKOCn",
        "outputId": "831843d1-c55c-405e-a0ba-8e085445499b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install JPype1-0.6.3-cp36-cp36m-win_amd64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjsdjO6wKViO",
        "outputId": "656c6484-2102-4eda-834a-93473a799703"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Requirement 'JPype1-0.6.3-cp36-cp36m-win_amd64.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: JPype1-0.6.3-cp36-cp36m-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHokwkuxKZGm",
        "outputId": "3f227d0c-2c47-4207-f835-2a6b7e486e29"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Error loading d: Package 'd' not found in index\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> x\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "EdJh-xHxKblC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EReQ6oWmKgeR",
        "outputId": "b6ff8c60-7e4a-414a-86ac-205ff338fcb9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "FWeqMVc1KiF3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. NLTK에서 불용어 확인하기"
      ],
      "metadata": {
        "id": "Vb0GmEgiKvHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_list = stopwords.words('english')\n",
        "print('불용어 개수 :', len(stop_words_list))\n",
        "print('불용어 10개 출력 :', stop_words_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV_tY53uKyyl",
        "outputId": "42478e05-1c9b-43ed-c5b4-61d3ca3252fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 개수 : 179\n",
            "불용어 10개 출력 : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. NLTK를 통해서 불용어 제거하기"
      ],
      "metadata": {
        "id": "9_nChZW-LdXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"Family is not an important thing. It's everything.\"\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "TmIBx6U7NFbf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = word_tokenize(example)"
      ],
      "metadata": {
        "id": "rn4BVsCiNORx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for word in word_tokens:\n",
        "  if word not in stop_words:\n",
        "    result.append(word)\n",
        "\n",
        "print('불용어 제거 전 :', word_tokens)\n",
        "print('불용어 제거 후 :', result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyx4M9ciNQzy",
        "outputId": "1d4911bf-be18-4dfb-f186-62668aded350"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 전 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
            "불용어 제거 후 : ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 한국어에서 불용어 제거하기"
      ],
      "metadata": {
        "id": "oqVf6AtfNbwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()"
      ],
      "metadata": {
        "id": "PONJBA2-brAB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은게 아니거든. 예컨데 삼겹살을 구울 때는 중요한 게 있지.\"\n",
        "stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\""
      ],
      "metadata": {
        "id": "jLbas7x_bzcm"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stop_words.split(' '))\n",
        "word_tokens = okt.morphs(example)"
      ],
      "metadata": {
        "id": "u2yLrRA5b6cr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = [word for word in word_tokens if not word in stop_words]"
      ],
      "metadata": {
        "id": "St4R_C9vfJm7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('불용어 제거 전 :',word_tokens)\n",
        "print('불용어 제거 후 :',result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLP5Dr8IfLmi",
        "outputId": "ca076feb-6099-4eab-f20d-81e463c23e10"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 전 : ['고기', '를', '아무렇게나', '구', '우려', '고', '하면', '안', '돼', '.', '고기', '라고', '다', '같은게', '아니거든', '.', '예컨데', '삼겹살', '을', '구울', '때', '는', '중요한', '게', '있지', '.']\n",
            "불용어 제거 후 : ['고기', '하면', '.', '고기', '라고', '다', '같은게', '아니거든', '.', '예컨데', '삼겹살', '을', '중요한', '있지', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 링크는 보편적으로 선택할 수 있는 한국어 불용어 리스트를 보여줍니다. 하지만 여전히 절대적인 기준은 아닙니다.\n",
        "\n",
        "링크 : https://www.ranks.nl/stopwords/korean\n",
        "\n",
        "불용어가 많은 경우에는 코드 내에서 직접 정의하지 않고 txt 파일이나 csv 파일로 정리해놓고 이를 불러와서 사용하기도 합니다."
      ],
      "metadata": {
        "id": "ekEgj3VFdPTU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "02PDsUmpfRzI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}